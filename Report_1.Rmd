---
title: "Info813 report I: Can we predict radiology visits using patient visiting data?"
author: Kai Li
date: April 4, 2016
output: md_document
---

#Info813 report I: Can we predict radiology visits using patient visting data?

Kai Li

Last update: 4/6/2016

## Problem statement

Two broad groups of questions will be addressed in this report:

1. What is the strongest determinant of the variable radiology visit among the three variables of patient days, emergency room visits, and clinic visits? And how to describe this relationship?

2. After regress radiology visits on the three other variables, how do your conclusion change regarding the relationship between the dependent variable and each independent variable?

## Data description

The original dataset includes 5 variables and 31 observations. The 5 variables are **identifier**, **radiology visits (rad vis)**, **patient days (p days)**, **emergency room visits (er vis)**, **and clinic visits (cl vis)**. Except for the identifier being a nominal variable, all the other 4 variables are ratio variables. A basic descriptive analysis was conducted over these four variables as below:

```{r setup, echo = FALSE, warning=FALSE}

library(foreign)
library(psych)

data <- read.spss("radiology.sav")
data <- data.frame(data)
colnames(data) <- c("id", "rad_vis", "p_days", "er_vis", "cl_vis")

describeBy(data[, c(2:5)])

data$rad_std <- (data$rad_vis - mean(data$rad_vis)) / sd(data$rad_vis)
data$rad_log <- log10(data$rad_vis)
data$rad_log2 <- log2(data$rad_vis)

```

Histograms of the dependent variable and log2 of the dependent variable were plotted below. Even though the distribution of log2 seems to be more normal than the original variable, the original variable of radiology visits will be used to do the correlation and regression tests, with the other one used to validate the results. 

``` {R fig.width = 7, fig.height = 4, echo = FALSE, warning=FALSE}

par(mfrow = c(1,2))

hist(data$rad_vis, main = "Histogram of radiology visits", xlab = "Radiology visit")
hist(data$rad_log2, main = "Histogram of radiology visits (log2)", xlab = "log2 of Radiology visit")

```

## Analytical method

To answer the research questions, correlation test and regression test were conducted over the dataset. 

The correlation test was conducted between the dependent variable, radiology visits, and the three independent variables, separately.

The regression test was conducted to test the model between the dependent variable, radiology visits, and the three independent variables together. Based on its result, a new model was proposed and tested, the results of which were compared with the first model.

## Results

#### Correlation

To answer the first question, the correlation between variables, the three scatter plots between the dependent variable and three independent variables were plotted as below:

``` {R fig.width = 7, fig.height = 8, echo = FALSE, warning=FALSE}

par(mfrow = c(2,2))

plot(data$rad_vis ~ data$p_days, xlab = "Patient days", ylab = "Radiology visits")
plot(data$rad_vis ~ data$er_vis, xlab = "Emergency visits", ylab = "Radiology visits")
plot(data$rad_vis ~ data$cl_vis, xlab = "Clinic visits", ylab = "Radiology visits")

```

Just by looking, emergency room visits is the variable that can best predict radiology visits, because the dots on the second scatter plot are the closest around the virtual regression line. The closeness can be best measured by R-squared value, or the goodness of fit. Below are the calculated R value and corresponding p-values between radiology visits and the three independent variables:

```{R echo = FALSE, warning=FALSE}

r1 <- cor.test(data$rad_vis, data$p_days)
r2 <- cor.test(data$rad_vis, data$er_vis)
r3 <- cor.test(data$rad_vis, data$cl_vis)

library(pander)

cor_table <- data.frame(c("Patient days", "Emergency room visits", "Clinic visits"),
                        c(r1$estimate ^ 2, r2$estimate ^ 2, r3$estimate ^ 2),
                        c(r1$p.value, r2$p.value, r3$p.value))
colnames(cor_table) <- c("Variable", "R-squared", "p-value")
pander(cor_table)

```

The above visual observation is supported by the calculated R-squared value, leading to the conclusion that the correlation between radiology visits and emergency room visits is the strongest among the three independent variables.

As a validation of the results, the scatter plots using log2 of the radiology visits and their R-squared values and p-values are listed below:

``` {R fig.width = 7, fig.height = 8, echo = FALSE, warning=FALSE}

par(mfrow = c(2,2))

plot(data$rad_log2 ~ data$p_days, xlab = "Patient days", ylab = "Radiology visits (log2)")
plot(data$rad_log2 ~ data$er_vis, xlab = "Emergency visits", ylab = "Radiology visits (log2)")
plot(data$rad_log2 ~ data$cl_vis, xlab = "Clinic visits", ylab = "Radiology visits (log2)")

r1 <- cor.test(data$rad_log2, data$p_days)
r2 <- cor.test(data$rad_log2, data$er_vis)
r3 <- cor.test(data$rad_log2, data$cl_vis)

library(pander)

cor_table <- data.frame(c("Patient days", "Emergency room visits", "Clinic visits"),
                        c(r1$estimate ^ 2, r2$estimate ^ 2, r3$estimate ^ 2),
                        c(r1$p.value, r2$p.value, r3$p.value))
colnames(cor_table) <- c("Variable", "R-squared", "p-value")
pander(cor_table)

```

It is obvious that using the original radiology visits variable and log2 of the same variable does not create much difference.

#### Regression

In order to create a regression model between radiology visit and three other independent variables, the following assumptions must be met ("Regression diagnostic", n.d.), which will be addressed later in this report.

1. linearity of the relationship between dependent and independent variables
2. independence of the errors
3. constant variance of the errors
4. normality of the errors
5. not multi-collinearity

The following model was established between the dependent variable, radiology visits, and the three independent variables, patient days, emergency room visits, and clinical visits.

``` {R}

lm <- lm(rad_vis ~ p_days + er_vis + cl_vis, data = data)

```

However, in order to determine if this model met all the assumptions of regression model, diagnostic plots were drawn below:

``` {R echo = FALSE, warning = FALSE, fig.width = 7, fig.height = 8}

par(mfrow = c(2,2))
plot(lm, which = 1:4)

```

According to the first plot, *residuals vs. fitted values*, the **linearity assumption** is largely not met by this model, because the values are not so equally distributed across the 0 line. Moreover, the **homoscedasticity assumption** may not be well met as well, because the trend line is not very parallel to the x-axis as well. The third plot, *scale-location plot* can be used to test the same assumption, even though the results are not clear. However, based on the results of Breusch-Pagan test, the null hypothesis of homoscedasticity cannot be rejected despite of the visual evidences:

``` {R echo = FALSE, warning = FALSE}

library(car)

ncvTest(lm)

```

Based on the second plot, *QQ Plot*, the **normality assumption** is also not met, because of the distances between the standardized residuals and the 45-degree line.

*Cook's distance plot* can be used to identify **influential outliers**. In our case, value 23 not only has a relatively big value (close to 1), but also stands out in some other plots. As a result, it is an influential outlier in our dataset. However, since we cannot double check the data collection procedures, nothing can be done to fix it.

The **independence assumption** was examined by Durbin-Watson test as below. Because the p-value is higher than 0.05, at 95% of confidence interval, the null hypothesis that the errors are uncorrelated cannot be rejected.

``` {R echo = F, warning = F}

library(lmtest)
dwtest(lm)

```

Last but not least, **multi-collinearity** was tested using *variance inflation factors* as below. The results for any of the three independent variables are under 4, which is the rule of thumb, meaning that the none-multi-collinearity assumption is met.

``` {R echo = F, warning = F}

vif(lm)

```

Despite of the possible issue in normality assumption, the summary of our original model is presented below:

``` {R echo = FALSE, warning = FALSE}

f <- summary(lm)
f

```

The results indicate that the overall model is valid at 95% of confidence interval, because p-value is smaller than 0.05, and F-value is larger than the critical F-value (3, 27). And in terms of the predictors, like the correlation analysis shows, emergency room visits is the strongest predictor. Patient days is another valid predictor at 99.999% of confidence interval. However, the null hypothesis that there is no linear correlation between radiology visits and clinical visits cannot be rejected at 95% of confidence interval, despite of the results of correlation analysis.

To validate the results of this model, a new model was proposed using the same variables, but radiology visits was transformed by log2. Below are the diagnostic plots of this new model and its summary.

``` {R echo = FALSE, warning = FALSE, fig.width = 7, fig.height = 8}

lm_log <- lm(rad_log2 ~ p_days + er_vis + cl_vis, data = data)

par(mfrow = c(2,2))
plot(lm_log, which = 1:4)

t <- summary(lm_log)
t

````

It is clear that the range of standard residuals in this new model is even larger than the original model; while the other requirements are not met in a better way.

To compare with our initial model, especially because clinic visits was not a significant predictor, a new model using radiology visits and the two valid independent variables, patient days and emergency room visits were created:

```{R}

lm_new <- lm(rad_vis ~ p_days + er_vis, data = data)

```

Below are its diagnostic plots, which show similar results as our initial model.

``` {R echo = FALSE, warning = FALSE, fig.width = 7, fig.height = 8}

par(mfrow = c(2,2))
plot(lm_new, which = 1:4)

```

And below is the summary of this new model.

``` {R echo = FALSE, warning = FALSE}

r <- summary(lm_new)
r

```

Based on the equation to compare the fitness of two regression models on page 68 of the book, the resulting F-value is:

``` {R echo = FALSE, warning = FALSE}

F_value <- ((f$r.squared - r$r.squared)/(r$df[2] - f$df[2])) / ((1 - f$r.squared) / f$df[2])
F_value

```

The critical F-value (1, 27) at 95% of confidence interval is 4.21, which is larger than the F-value comparing the two models. As a result, we cannot draw the conclusion that the new model with two independent variables is significantly better than our initial model.

Just for comparison, another test of fitness was conducted between our initial model and the model using log2 as the dependent variable. Below is the F value of this comparison:

``` {R echo = FALSE, warning = FALSE}

F_value <- ((t$r.squared - r$r.squared)/(r$df[2] - t$df[2])) / ((1 - t$r.squared) / t$df[2])
F_value

```

Similarly, despite of the seeming increased F value in our last model, the conclusion, again, fails to prove that there is a significant improvement in the latter model.

#### Validation of the regression model

In order to further validate the model, Jackknife validation method was adopted to test if our original model was valid in general. The table below shows the coefficiencies of the original model after each observation is removed.

``` {R echo = F, warning = F}

val_table <- data.frame()

for (i in 1:31) {
  data_sample <- data[-i,]
  lm_sample <- summary(lm(rad_vis ~ p_days + er_vis + cl_vis, data = data_sample))
  val_table[i, 1] <- i
  val_table[i, 2] <- lm_sample$coefficients[[1]]
  val_table[i, 3] <- lm_sample$coefficients[[2]]
  val_table[i, 4] <- lm_sample$coefficients[[3]]
  val_table[i, 5] <- lm_sample$coefficients[[4]]
}

colnames(val_table) <- c("Obs", "Intercept", "p_day", "er_vis", "cl_vis")

pander(val_table)

```

## Conclusions

As is shown by our analysis, **emergency room visits** is the variable that most strongly correlates with radiology visits, in both tests. And despite of its strong correlation in the first test, **clinic visits** was found not to be able to predict radiology visits in our regression model, which might be because of multi-collinearity. The results concerning patient days did not change in these two tests.

Another conclusion is that, despite of removing an independent variable that is proven not to be able to predict the dependent variable, our new model isn't significantly better than the original one, despite of an increased F value.